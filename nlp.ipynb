{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21641,
     "status": "ok",
     "timestamp": 1751691130441,
     "user": {
      "displayName": "12317014 ANIX SAJU",
      "userId": "10266061809267748645"
     },
     "user_tz": -330
    },
    "id": "DbtidsPZrk9V",
    "outputId": "e510e96d-85a3-4a22-cc98-84030b420314"
   },
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "!pip install spacy nltk transformers torch\n",
    "\n",
    "\n",
    "# Install the spaCy English model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Download NLTK data\n",
    "!python -m nltk.downloader punkt wordnet omw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20222,
     "status": "ok",
     "timestamp": 1751691168463,
     "user": {
      "displayName": "12317014 ANIX SAJU",
      "userId": "10266061809267748645"
     },
     "user_tz": -330
    },
    "id": "PwD4G2q4shSL",
    "outputId": "d26c448d-f3a5-4bc6-c017-b4bbe90e8993"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û°Ô∏è Processing: BERT is a transformer-based model developed by Google.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Entities: ['BERT', 'Google']\n",
      "   Generated Q/A: What is a transformer-based model developed by Google? / BERT\n",
      "   Distractors: []\n",
      "‚û°Ô∏è Processing: It is widely used for natural language processing tasks such as question answering and text classification.\n",
      "   Entities: []\n",
      "‚û°Ô∏è Processing: The Eiffel Tower was constructed in 1889 for the World's Fair in Paris.\n",
      "   Entities: ['Eiffel Tower', \"World ' s Fair\", 'Paris']\n",
      "   Generated Q/A: What was built for the World's Fair in Paris? / Eiffel Tower\n",
      "   Distractors: []\n",
      "\n",
      "üéì Generated MCQs:\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "# Ensure required NLTK data is available\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "# ‚Äî‚Äî‚Äî Setup ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "ner = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "model_name = \"fares7elsadek/t5-base-finetuned-question-generation\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "qg_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def generate_qa(context: str, answer: str = \"[MASK]\", max_len=64):\n",
    "    input_text = f\"context: {context} answer: {answer} </s>\"\n",
    "    inputs = tokenizer([input_text], return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    output = qg_model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=max_len,\n",
    "        num_beams=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"question:\" in text and \"answer:\" in text:\n",
    "        q, a = text.split(\"answer:\")\n",
    "        return q.replace(\"question:\", \"\").strip(), a.strip()\n",
    "    if \"?\" in text:\n",
    "        q, a = text.split(\"?\", 1)\n",
    "        return (q + \"?\").strip(), a.strip()\n",
    "    return None, None\n",
    "\n",
    "def get_distractors_wordnet(word):\n",
    "    key = word.replace(\" \", \"_\")\n",
    "    synsets = wordnet.synsets(key, pos='n')\n",
    "    if not synsets:\n",
    "        return []\n",
    "    hyper = synsets[0].hypernyms()\n",
    "    if not hyper:\n",
    "        return []\n",
    "    hypos = hyper[0].hyponyms()\n",
    "    distros = [lemma.name().replace(\"_\", \" \") for h in hypos for lemma in h.lemmas()]\n",
    "    return list(set(distros) - {word})[:3]\n",
    "\n",
    "def generate_mcqs(text: str, num_questions=5):\n",
    "    doc = nlp(text)\n",
    "    sentences = [s.text.strip() for s in doc.sents if len(s.text.split()) >= 6]\n",
    "    mcqs = []\n",
    "\n",
    "    for sent in random.sample(sentences, min(num_questions, len(sentences))):\n",
    "        print(\"‚û°Ô∏è Processing:\", sent)\n",
    "        ents = [e['word'] for e in ner(sent) if e['entity_group'] in (\"PER\",\"LOC\",\"ORG\",\"MISC\")]\n",
    "        print(\"   Entities:\", ents)\n",
    "        if not ents:\n",
    "            continue\n",
    "\n",
    "        answer_ent = ents[0]\n",
    "        question, answer = generate_qa(sent, answer=answer_ent)\n",
    "        print(\"   Generated Q/A:\", question, \"/\", answer)\n",
    "        if not question or not answer:\n",
    "            continue\n",
    "\n",
    "        distractors = get_distractors_wordnet(answer)\n",
    "        print(\"   Distractors:\", distractors)\n",
    "        if len(distractors) < 3:\n",
    "            continue\n",
    "\n",
    "        options = [answer] + random.sample(distractors, 3)\n",
    "        random.shuffle(options)\n",
    "        correct = chr(65 + options.index(answer))\n",
    "        mcqs.append({\n",
    "            \"question\": question,\n",
    "            \"options\": options,\n",
    "            \"answer\": correct\n",
    "        })\n",
    "\n",
    "    return mcqs\n",
    "\n",
    "# ‚Äî‚Äî‚Äî Test Run ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"\"\"\n",
    "    BERT is a transformer-based model developed by Google. It is widely used for natural language processing tasks such as question answering and text classification.\n",
    "    The Eiffel Tower was constructed in 1889 for the World's Fair in Paris.\n",
    "    \"\"\"\n",
    "    mcqs = generate_mcqs(sample_text, num_questions=3)\n",
    "    print(\"\\nüéì Generated MCQs:\")\n",
    "    for i, q in enumerate(mcqs, 1):\n",
    "        print(f\"Q{i}. {q['question']}\")\n",
    "        for idx, opt in enumerate(q['options'], start=65):\n",
    "            print(f\"   {chr(idx)}) {opt}\")\n",
    "        print(f\"Answer: {q['answer']}\\n{'-'*40}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
